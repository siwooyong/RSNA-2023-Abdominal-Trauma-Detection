{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:37.226766Z",
     "iopub.status.busy": "2023-10-05T20:45:37.226480Z",
     "iopub.status.idle": "2023-10-05T20:45:37.232527Z",
     "shell.execute_reply": "2023-10-05T20:45:37.231983Z",
     "shell.execute_reply.started": "2023-10-05T20:45:37.226750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "datadir = './input'\n",
    "libdir = '.'\n",
    "outputdir = './output'\n",
    "otherdir = '.'\n",
    "train_bs_ = 4\n",
    "valid_bs_ = 8\n",
    "num_workers_ = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:37.233767Z",
     "iopub.status.busy": "2023-10-05T20:45:37.233448Z",
     "iopub.status.idle": "2023-10-05T20:45:37.239366Z",
     "shell.execute_reply": "2023-10-05T20:45:37.238805Z",
     "shell.execute_reply.started": "2023-10-05T20:45:37.233752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed=42\n",
    "    device='GPU'\n",
    "    nprocs=1 # [1, 8]\n",
    "    num_workers=num_workers_\n",
    "    train_bs=train_bs_\n",
    "    valid_bs=valid_bs_\n",
    "    data_dir = './'\n",
    "    target_cols=['bowel_healthy', 'bowel_injury', 'extravasation_healthy',\n",
    "       'extravasation_injury', 'kidney_healthy', 'kidney_low', 'kidney_high',\n",
    "       'liver_healthy', 'liver_low', 'liver_high', 'spleen_healthy',\n",
    "       'spleen_low', 'spleen_high']\n",
    "    imgs_dir = ['./input/']\n",
    "    num_classes=13\n",
    "\n",
    "    accum_iter=2\n",
    "    max_grad_norm=1000\n",
    "    print_freq=100\n",
    "    normalize_mean=[0.4824, 0.4824, 0.4824] # [0.485, 0.456, 0.406] [0.4824, 0.4824, 0.4824]\n",
    "    normalize_std=[0.22, 0.22, 0.22] # [0.229, 0.224, 0.225] [0.22, 0.22, 0.22]\n",
    "\n",
    "    suffix=\"440\" \n",
    "    fold_num=5\n",
    "    fold_list=[2, 3, 4]\n",
    "    min_epoch = -1\n",
    "    epochs = 20\n",
    "    model_arch=\"resnest50d\" # tf_efficientnetv2_s, resnest50d, resnext50_32x4d, resnet200d\n",
    "    optimizer=\"AdamW\" # Adam, SGD, AdamW\n",
    "    scheduler=\"CosineAnnealingLR\"#'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts'\n",
    "    loss_fn= \"BCEWithLogitsLoss\"#'Custom_loss', \"BCEWithLogitsLoss\", \"FocalLoss\"\n",
    "    scheduler_warmup=\"GradualWarmupSchedulerV3\" \n",
    "\n",
    "    warmup_epo=1\n",
    "    warmup_factor = 10\n",
    "    T_max= epochs-warmup_epo-2 \n",
    "    \n",
    "    seq_len = 96\n",
    "    img_size=256\n",
    "    p_mixup = 0\n",
    "\n",
    "    lr=5e-5\n",
    "    min_lr=1e-7\n",
    "    # lr=23e-5\n",
    "    # min_lr=23e-6\n",
    "    weight_decay=0.02\n",
    "    dropout=0.1\n",
    "\n",
    "    gpu_parallel=False\n",
    "    n_early_stopping=5\n",
    "    debug=False\n",
    "    multihead=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:37.240359Z",
     "iopub.status.busy": "2023-10-05T20:45:37.240010Z",
     "iopub.status.idle": "2023-10-05T20:45:37.244804Z",
     "shell.execute_reply": "2023-10-05T20:45:37.244300Z",
     "shell.execute_reply.started": "2023-10-05T20:45:37.240345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [i for i in timm.list_models(pretrained=True) if 'tf_efficientnet_b5' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:37.246079Z",
     "iopub.status.busy": "2023-10-05T20:45:37.245906Z",
     "iopub.status.idle": "2023-10-05T20:45:37.248619Z",
     "shell.execute_reply": "2023-10-05T20:45:37.248114Z",
     "shell.execute_reply.started": "2023-10-05T20:45:37.246065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install warmup-scheduler==0.3\n",
    "# !pip install timm==0.9.7\n",
    "# !pip install nibabel==5.1.0\n",
    "# !pip install pydicom==2.4.3\n",
    "# !pip install albumentations==1.3.1\n",
    "# !pip install numpy==1.26.0\n",
    "# !pip install transformers==4.34.0\n",
    "# !pip install torchvision==0.15.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:37.249446Z",
     "iopub.status.busy": "2023-10-05T20:45:37.249273Z",
     "iopub.status.idle": "2023-10-05T20:45:40.180855Z",
     "shell.execute_reply": "2023-10-05T20:45:40.180317Z",
     "shell.execute_reply.started": "2023-10-05T20:45:37.249431Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/tmp/ipykernel_4043/3231748879.py:43: DeprecationWarning: Please use `zoom` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import zoom\n"
     ]
    }
   ],
   "source": [
    "import sys; \n",
    "\n",
    "package_paths = [f'{libdir}pytorch-image-models-master']\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "import ast\n",
    "from glob import glob\n",
    "import cv2\n",
    "# from skimage import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import nibabel as nib\n",
    "import pydicom as dicom\n",
    "import gc \n",
    "from torch.nn import DataParallel\n",
    "\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n",
    "    CenterCrop, Resize, RandomCrop, GaussianBlur, JpegCompression, Downscale, ElasticTransform\n",
    ")\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    !pip install -q pytorch-ignite\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.182452Z",
     "iopub.status.busy": "2023-10-05T20:45:40.181736Z",
     "iopub.status.idle": "2023-10-05T20:45:40.203218Z",
     "shell.execute_reply": "2023-10-05T20:45:40.202661Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.182427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "\n",
    "\n",
    "class Custom_loss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Custom_loss, self).__init__()\n",
    "        self.ll = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        y_pred = y_pred.sigmoid()\n",
    "        nm = y_pred.clone()\n",
    "\n",
    "        nm[:, 0], nm[:, 1] = [nm[:, 0] + nm[:, 1]]*2\n",
    "        nm[:, 2], nm[:, 3] = [nm[:, 2] + nm[:, 3]]*2\n",
    "        nm[:, 4], nm[:, 5], nm[:, 6] = [nm[:, 4] + nm[:, 5] + nm[:, 6]]*3\n",
    "        nm[:, 7], nm[:, 8], nm[:, 9] = [nm[:, 7] + nm[:, 8] + nm[:, 9]]*3\n",
    "        nm[:, 10], nm[:, 11], nm[:, 12] = [nm[:, 10] + nm[:, 11] + nm[:, 12]]*3\n",
    "\n",
    "        any_injury_labels = 1 - y_true[:, 0]\n",
    "        any_injury_preds = 1 - (y_pred[:, 0]/nm[:, 0])\n",
    "        for i in [2, 4, 7, 10]:\n",
    "            any_injury_labels = torch.maximum(any_injury_labels, 1 - y_true[:, i])\n",
    "            any_injury_preds = torch.maximum(any_injury_preds, 1 - (y_pred[:, i]/nm[:, i]))\n",
    "\n",
    "        w1 = y_true[:, 0] + 2 * y_true[:, 1]\n",
    "        w2 = y_true[:, 2] + 6 * y_true[:, 3]\n",
    "        w3 = y_true[:, 4] + 2 * y_true[:, 5] + 4 * y_true[:, 6]\n",
    "        w4 = y_true[:, 7] + 2 * y_true[:, 8] + 4 * y_true[:, 9]\n",
    "        w5 = y_true[:, 10] + 2 * y_true[:, 11] + 4 * y_true[:, 12]\n",
    "        w6 = 5*any_injury_labels + 1\n",
    "\n",
    "        l1 = (self.ll(y_pred[:, :2]/nm[:, :2], y_true[:, :2]).mean(1)*w1).sum()/w1.sum()\n",
    "        l2 = (self.ll(y_pred[:, 2:4]/nm[:, 2:4], y_true[:, 2:4]).mean(1)*w2).sum()/w2.sum()\n",
    "        l3 = (self.ll(y_pred[:, 4:7]/nm[:, 4:7], y_true[:, 4:7]).max(1).values*w3).sum()/w3.sum()\n",
    "        l4 = (self.ll(y_pred[:, 7:10]/nm[:, 7:10], y_true[:, 7:10]).max(1).values*w4).sum()/w4.sum()\n",
    "        l5 = (self.ll(y_pred[:, 10:13]/nm[:, 10:13], y_true[:, 10:13]).max(1).values*w5).sum()/w5.sum()\n",
    "        l6 = (self.ll(any_injury_preds, any_injury_labels)*w6).sum()/w6.sum()\n",
    "\n",
    "\n",
    "        return (l1 + l2 + l3 + l4 + l5 + l6)/6\n",
    "    \n",
    "    \n",
    "\n",
    "def comp_metric_score(solution, submission):\n",
    "\n",
    "    label_group_losses = []\n",
    "\n",
    "    ws = solution[:, 0] + 2*solution[:, 1]\n",
    "    s = submission[:, 0] + submission[:, 1]\n",
    "    submission[:, 0], submission[:, 1] = submission[:, 0]/s, submission[:, 1]/s\n",
    "    label_group_losses.append(\n",
    "            log_loss(y_true=solution[:, :2], y_pred=submission[:, :2], sample_weight=ws)\n",
    "        )\n",
    "\n",
    "\n",
    "    ws = solution[:, 2] + 6*solution[:, 3]\n",
    "    s = submission[:, 2] + submission[:, 3]\n",
    "    submission[:, 2], submission[:, 3] = submission[:, 2]/s, submission[:, 3]/s\n",
    "    label_group_losses.append(\n",
    "            log_loss(y_true=solution[:, 2:4], y_pred=submission[:, 2:4], sample_weight=ws)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(3):\n",
    "        ws = solution[:, 4 + 3*i] + 2*solution[:, 5 + 3*i] + 4*solution[:, 6 + 3*i]\n",
    "        s = submission[:, 4 + 3*i] + submission[:, 5 + 3*i] + submission[:, 6 + 3*i]\n",
    "        submission[:, 4 + 3*i], submission[:, 5 + 3*i], submission[:, 6 + 3*i] = submission[:, 4 + 3*i]/s, submission[:, 5 + 3*i]/s, submission[:, 6 + 3*i]/s\n",
    "        label_group_losses.append(\n",
    "                log_loss(y_true=solution[:, 4 + 3*i:4 + 3*(i+1)], \n",
    "                                         y_pred=submission[:, 4 + 3*i:4 + 3*(i+1)], \n",
    "                                         sample_weight=ws)\n",
    "            )\n",
    "\n",
    "        \n",
    "    any_injury_labels = 1 - solution[:, 0]\n",
    "    any_injury_preds = 1 - submission[:, 0]\n",
    "    for i in [2, 4, 7, 10]:\n",
    "        any_injury_labels = np.maximum(any_injury_labels, 1 - solution[:, i])\n",
    "        any_injury_preds = np.maximum(any_injury_preds, 1 - submission[:, i])\n",
    "    \n",
    "    label_group_losses.append(log_loss(\n",
    "        y_true=any_injury_labels, y_pred=any_injury_preds, sample_weight=ws ))\n",
    "    \n",
    "    ws = 5*any_injury_labels + 1#5*solution[:, 13] + 1\n",
    "    \n",
    "    return np.mean(label_group_losses)\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.205505Z",
     "iopub.status.busy": "2023-10-05T20:45:40.205138Z",
     "iopub.status.idle": "2023-10-05T20:45:40.210702Z",
     "shell.execute_reply": "2023-10-05T20:45:40.210227Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.205481Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_pickle(f'{datadir}/vertebrae_df.pkl')\n",
    "# submission_df = pd.read_csv(f'{datadir}/sample_submission.csv')\n",
    "\n",
    "# train_df = train_df[~train_df[\"StudyInstanceUID\"].isin([\"1.2.826.0.1.3680043.20574\", \"1.2.826.0.1.3680043.29952\"]) ].reset_index(drop=True)\n",
    "\n",
    "# gkf = GroupKFold(n_splits=CFG.fold_num)\n",
    "# folds = gkf.split(X=train_df, y=None, groups=train_df['StudyInstanceUID'])\n",
    "\n",
    "\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.211640Z",
     "iopub.status.busy": "2023-10-05T20:45:40.211404Z",
     "iopub.status.idle": "2023-10-05T20:45:40.289399Z",
     "shell.execute_reply": "2023-10-05T20:45:40.288865Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.211618Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENV = 'kaggle'\n",
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    VERSION = \"1.7\"\n",
    "    CP_V = \"36\" if ENV == \"colab\" else \"37\"\n",
    "    wheel = f\"torch_xla-{VERSION}-cp{CP_V}-cp{CP_V}m-linux_x86_64.whl\"\n",
    "    url = f\"https://storage.googleapis.com/tpu-pytorch/wheels/{wheel}\"\n",
    "    !pip3 -q install cloud-tpu-client==0.10 $url\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.train_bs = CFG.train_bs // CFG.nprocs\n",
    "    device = xm.xla_device()\n",
    "    \n",
    "elif CFG.device == \"GPU\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.290432Z",
     "iopub.status.busy": "2023-10-05T20:45:40.290204Z",
     "iopub.status.idle": "2023-10-05T20:45:40.303855Z",
     "shell.execute_reply": "2023-10-05T20:45:40.303383Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.290411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=outputdir+'stage2_train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger(outputdir+f'/stage2_train{CFG.suffix}.log')\n",
    "\n",
    "if CFG.device=='TPU' and CFG.nprocs==8:\n",
    "    loginfo = xm.master_print\n",
    "    cusprint = xm.master_print\n",
    "else:\n",
    "    loginfo = LOGGER.info\n",
    "    cusprint = print\n",
    "\n",
    "\n",
    "\n",
    "def get_timediff(time1,time2):\n",
    "    minute_,second_ = divmod(time2-time1,60)\n",
    "    return f\"{int(minute_):02d}:{int(second_):02d}\"  \n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    # data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.305037Z",
     "iopub.status.busy": "2023-10-05T20:45:40.304797Z",
     "iopub.status.idle": "2023-10-05T20:45:40.328211Z",
     "shell.execute_reply": "2023-10-05T20:45:40.327721Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.305015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class TrainDataset(Dataset):\n",
    "#     def __init__(self, df, transform=None):\n",
    "#         self.df = df\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         row = self.df.iloc[idx]\n",
    "#         study_id = row[\"StudyInstanceUID\"]\n",
    "#         slice_num_list = row['slice_num_list']\n",
    "#         before_image_size = row[\"before_image_size\"]\n",
    "#         y0 = row[\"y0\"]; y1 = row[\"y1\"];\n",
    "#         z0 = row[\"z0\"]; z1 = row[\"z1\"];\n",
    "\n",
    "#         slice_list = []\n",
    "#         for s_num in slice_num_list:\n",
    "#             path = f\"{datadir}/train_images/{study_id}/{s_num}.dcm\"\n",
    "#             img = load_dicom(path)\n",
    "#             if len(slice_list) == 0:\n",
    "#                 imgh = img.shape[0]\n",
    "#                 imgw = img.shape[1]\n",
    "#             elif img.shape != (imgh, imgw):\n",
    "#                 img = cv2.resize(img,(imgh,imgw))\n",
    "\n",
    "#             slice_list.append(img)\n",
    "#         for _ in range(CFG.seq_len - len(slice_list)):\n",
    "#             slice_list.append(np.zeros((imgh,imgw)))\n",
    "\n",
    "#         image = np.stack(slice_list, axis=2) # 512*512*seq_len; 0-1\n",
    "#         image = cv2.resize(image, (before_image_size, before_image_size))\n",
    "#         image = image[y0:y1, z0:z1, :]\n",
    "\n",
    "#         # transform\n",
    "#         if self.transform:\n",
    "#             augmented = self.transform(image=image)\n",
    "#             image = augmented['image']\n",
    "\n",
    "#         image = np.transpose(image, (2, 0, 1)) # seq_len*img_size*img_size; 0-1\n",
    "#         return torch.from_numpy(image), torch.tensor(row['label']).float()\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv, targets, mode, meta_features, in_chans, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.targets = targets\n",
    "        self.mode = mode\n",
    "        self.use_meta = meta_features is not None\n",
    "        self.meta_features = meta_features\n",
    "        self.transform = transform\n",
    "        self.in_chans = in_chans\n",
    "        self.aug_tr = v2.RandomRotation(\n",
    "                            degrees = (-45, 45),\n",
    "                            interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
    "                            expand = False,\n",
    "                            center = None,\n",
    "                            fill = 0\n",
    "                        )\n",
    "        self.aug_sj = v2.ScaleJitter(\n",
    "                        target_size = [CFG.img_size, CFG.img_size],\n",
    "                        scale_range = (0.8, 1.2),\n",
    "                        interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
    "                        antialias = True)\n",
    "        self.aug_rc = v2.RandomCrop(\n",
    "                            size = [CFG.img_size, CFG.img_size],\n",
    "                            #padding = None,\n",
    "                            pad_if_needed = True,\n",
    "                            fill = 0,\n",
    "                            padding_mode = 'constant'\n",
    "                        )\n",
    "        self.aug_hf = v2.RandomHorizontalFlip(0.5)\n",
    "        self.aug_vf = v2.RandomVerticalFlip(0.5)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        fp = f'{datadir}/{int(row.patient_id)}_{int(row.series_id)}.pt'\n",
    "        image = torch.load(fp).float()/255\n",
    "\n",
    "        if(self.mode == 'train'):\n",
    "            if np.random.rand()<0.5:\n",
    "                image = self.aug_tr(image)\n",
    "                image = self.aug_sj(image)\n",
    "                image = self.aug_rc(image)\n",
    "                inds = np.random.choice(np.arange(1, CFG.seq_len-1), CFG.seq_len//3, replace = False)\n",
    "                inds.sort()\n",
    "                inds = np.stack([inds-1, inds, inds+1]).T.flatten()\n",
    "                image = image[inds]\n",
    "            # image = self.aug_hf(image)\n",
    "            # image = self.aug_vf(image)\n",
    "\n",
    "\n",
    "        # transform\n",
    "        # if self.transform:\n",
    "            # image = image.numpy()\n",
    "            # image = np.transpose(image, (1, 2, 0))\n",
    "            # augmented = self.transform(image=image)\n",
    "            # image = augmented['image']\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.use_meta:\n",
    "            data = (image, torch.tensor(row[self.meta_features]).float())\n",
    "        else:\n",
    "            data = image\n",
    "            \n",
    "        if self.mode == 'test':\n",
    "            return row.patient_id, data\n",
    "        else:\n",
    "            return row.patient_id, data, torch.tensor(row[self.targets]).float()\n",
    "\n",
    "\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "    albumentations.Resize(CFG.img_size, CFG.img_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    # albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightness(limit=0.1, p=0.7),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.Cutout(max_h_size=int(CFG.img_size * 0.5), max_w_size=int(CFG.img_size * 0.5), num_holes=1, p=0.5),\n",
    "    # albumentations.Normalize()\n",
    "            ])\n",
    "    elif data == 'light_train':\n",
    "        return Compose([\n",
    "            Resize(CFG.img_size, CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20, p=0.5),\n",
    "            OneOf([\n",
    "                # GaussNoise(),\n",
    "                GaussianBlur(),\n",
    "                MotionBlur(),\n",
    "                # MedianBlur(),\n",
    "            ], p=0.3),\n",
    "            OneOf([\n",
    "                GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "                OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "                ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "            ], p=0.3),\n",
    "            # CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "            #              min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "            # albumentations.Normalize()\n",
    "            ], p=1.0)    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.img_size, CFG.img_size),\n",
    "            # albumentations.Normalize()\n",
    "        ])\n",
    "\n",
    "def get_meta_data(df_train, df_test):\n",
    "\n",
    "    # One-hot encoding of anatom_site_general_challenge feature\n",
    "    concat = pd.concat([df_train['anatom_site_general_challenge'], df_test['anatom_site_general_challenge']], ignore_index=True)\n",
    "    dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "    df_train = pd.concat([df_train, dummies.iloc[:df_train.shape[0]]], axis=1)\n",
    "    df_test = pd.concat([df_test, dummies.iloc[df_train.shape[0]:].reset_index(drop=True)], axis=1)\n",
    "    # Sex features\n",
    "    df_train['sex'] = df_train['sex'].map({'male': 1, 'female': 0})\n",
    "    df_test['sex'] = df_test['sex'].map({'male': 1, 'female': 0})\n",
    "    df_train['sex'] = df_train['sex'].fillna(-1)\n",
    "    df_test['sex'] = df_test['sex'].fillna(-1)\n",
    "    # Age features\n",
    "    df_train['age_approx'] /= 90\n",
    "    df_test['age_approx'] /= 90\n",
    "    df_train['age_approx'] = df_train['age_approx'].fillna(0)\n",
    "    df_test['age_approx'] = df_test['age_approx'].fillna(0)\n",
    "    df_train['patient_id'] = df_train['patient_id'].fillna(0)\n",
    "    # n_image per user\n",
    "    df_train['n_images'] = df_train.patient_id.map(df_train.groupby(['patient_id']).image_name.count())\n",
    "    df_test['n_images'] = df_test.patient_id.map(df_test.groupby(['patient_id']).image_name.count())\n",
    "    df_train.loc[df_train['patient_id'] == -1, 'n_images'] = 1\n",
    "    df_train['n_images'] = np.log1p(df_train['n_images'].values)\n",
    "    df_test['n_images'] = np.log1p(df_test['n_images'].values)\n",
    "    # image size\n",
    "    train_images = df_train['filepath'].values\n",
    "    train_sizes = np.zeros(train_images.shape[0])\n",
    "    for i, img_path in enumerate(tqdm(train_images)):\n",
    "        train_sizes[i] = os.path.getsize(img_path)\n",
    "    df_train['image_size'] = np.log(train_sizes)\n",
    "    test_images = df_test['filepath'].values\n",
    "    test_sizes = np.zeros(test_images.shape[0])\n",
    "    for i, img_path in enumerate(tqdm(test_images)):\n",
    "        test_sizes[i] = os.path.getsize(img_path)\n",
    "    df_test['image_size'] = np.log(test_sizes)\n",
    "\n",
    "    meta_features = ['sex', 'age_approx', 'n_images', 'image_size'] + [col for col in df_train.columns if col.startswith('site_')]\n",
    "    n_meta_features = len(meta_features)\n",
    "\n",
    "    return df_train, df_test, meta_features, n_meta_features\n",
    "\n",
    "\n",
    "def get_df(data_dir, use_meta):\n",
    "\n",
    "#     # 2020 data\n",
    "    df_train = pd.read_csv(os.path.join(CFG.data_dir, 'train_series_meta.csv')).merge(\n",
    "                    pd.read_csv(os.path.join(CFG.data_dir, 'train.csv')))\n",
    "    df_train['patient_id'] = df_train['patient_id'].astype(int)\n",
    "    df_train['series_id'] = df_train['series_id'].astype(int)\n",
    "    # df_train = df_train[(df_train['patient_id']!=63069)|((df_train['series_id']!=23719))].reset_index(drop = True)\n",
    "    # df_train = df_train[(df_train['patient_id']!=62847)|((df_train['series_id']!=16405))].reset_index(drop = True)\n",
    "    skf = StratifiedGroupKFold(n_splits = CFG.fold_num)\n",
    "    df_train['fold'] = -1\n",
    "    for i, (train_inds, val_inds) in enumerate(skf.split(df_train, df_train['bowel_healthy'], df_train['patient_id'])):\n",
    "        df_train.loc[val_inds, 'fold'] = i\n",
    "\n",
    "\n",
    "    df_test = df_train.iloc[:10].copy()\n",
    "\n",
    "    if use_meta:\n",
    "        df_train, df_test, meta_features, n_meta_features = get_meta_data(df_train, df_test)\n",
    "    else:\n",
    "        meta_features = None\n",
    "        n_meta_features = 0\n",
    "\n",
    "    return df_train#, df_test, meta_features, n_meta_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.329438Z",
     "iopub.status.busy": "2023-10-05T20:45:40.328970Z",
     "iopub.status.idle": "2023-10-05T20:45:40.334362Z",
     "shell.execute_reply": "2023-10-05T20:45:40.333906Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.329414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pylab import rcParams\n",
    "# dataset_show = TrainDataset(\n",
    "#     train_df,\n",
    "#     transform=get_transforms(data='light_train') # None, get_transforms(data='check')\n",
    "#     )\n",
    "# rcParams['figure.figsize'] = 30,20\n",
    "# for i in range(2):\n",
    "#     f, axarr = plt.subplots(1,5)\n",
    "#     idx = np.random.randint(0, len(dataset_show))\n",
    "#     img, label= dataset_show[idx]\n",
    "#     # axarr[p].imshow(img) # transform=None\n",
    "#     axarr[0].imshow(img[0]); plt.axis('OFF');\n",
    "#     axarr[1].imshow(img[1]); plt.axis('OFF');\n",
    "#     axarr[2].imshow(img[2]); plt.axis('OFF');\n",
    "#     axarr[3].imshow(img[3]); plt.axis('OFF');\n",
    "#     axarr[4].imshow(img[4]); plt.axis('OFF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.335310Z",
     "iopub.status.busy": "2023-10-05T20:45:40.335076Z",
     "iopub.status.idle": "2023-10-05T20:45:40.344659Z",
     "shell.execute_reply": "2023-10-05T20:45:40.344179Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.335289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from itertools import repeat\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Dict, Optional\n",
    " \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "    \n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        # print(f\"x shape:{x.shape}\")\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        # flat_inputs = x.reshape(-1, self.hidden_dim) # (batch_size*seq_len, hidden_dim)\n",
    "        # print(f\"flat_inputs shape:{flat_inputs.shape}\")\n",
    "        \n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        # print(f\"H shape:{H.shape}\")\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        # print(f\"att_scores shape:{att_scores.shape}\")\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        # print(f\"attn_x shape:{attn_x.shape}\")\n",
    "        return attn_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.345845Z",
     "iopub.status.busy": "2023-10-05T20:45:40.345416Z",
     "iopub.status.idle": "2023-10-05T20:45:40.355802Z",
     "shell.execute_reply": "2023-10-05T20:45:40.355236Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.345824Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n",
    "        super(GeM, self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1) * p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = gem(x, p=self.p, eps=self.eps)\n",
    "        return ret\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__\n",
    "            + \"(\"\n",
    "            + \"p=\"\n",
    "            + \"{:.4f}\".format(self.p.data.tolist()[0])\n",
    "            + \", \"\n",
    "            + \"eps=\"\n",
    "            + str(self.eps)\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "class RSNAClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, hidden_dim=256, seq_len=CFG.seq_len, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.model = timm.create_model(model_arch, in_chans=3, pretrained=pretrained)\n",
    "\n",
    "        if 'efficientnet' in CFG.model_arch:\n",
    "            cnn_feature = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "        elif \"res\" in CFG.model_arch:\n",
    "            cnn_feature = self.model.fc.in_features\n",
    "            self.model.global_pool = nn.Identity()\n",
    "            self.model.fc = nn.Identity()\n",
    "            \n",
    "            self.pooling = nn.AdaptiveAvgPool2d(1)#GeM(p_trainable=False)\n",
    "        \n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(cnn_feature, hidden_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.mlp_attention_layer = MLPAttentionNetwork(2 * hidden_dim)\n",
    "        self.logits = nn.Sequential(\n",
    "                # nn.Linear(512, 256),\n",
    "                # nn.BatchNorm1d(256),\n",
    "                # nn.Dropout(0.3),\n",
    "                # nn.LeakyReLU(0.1),\n",
    "                nn.Linear(256, len(CFG.target_cols)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # (B, seq_len, H, W)\n",
    "        bs = x.size(0)\n",
    "        \n",
    "        x = x.reshape(bs*self.seq_len//3, 3, x.size(2), x.size(3)) # (B*seq_len, 1, H, W)\n",
    "        features = self.model(x)\n",
    "        if \"res\" in CFG.model_arch:                             \n",
    "            features = self.pooling(features).view(bs*self.seq_len//3, -1) # (B*seq_len, cnn_feature)\n",
    "        features = self.spatialdropout(features)                # (B*seq_len, cnn_feature)\n",
    "        # print(features.shape)\n",
    "        features = features.reshape(bs, self.seq_len//3, -1)       # (B, seq_len, cnn_feature)\n",
    "        features, _ = self.gru(features)                        # (B, seq_len, hidden_dim*2)\n",
    "        features = self.mlp_attention_layer(features)          # (B, hidden_dim*2)\n",
    "        # features = features.contiguous().view(bs * (self.seq_len//3), -1)\n",
    "        pred = self.logits(features)                           # (B, 1)\n",
    "        # pred = pred.view(bs, self.seq_len//3 len(CFG.target_cols)).contiguous()\n",
    "        # pred = pred.mean(1)\n",
    "        pred = pred.view(bs, -1)                                # (B, 1)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.356790Z",
     "iopub.status.busy": "2023-10-05T20:45:40.356565Z",
     "iopub.status.idle": "2023-10-05T20:45:40.797362Z",
     "shell.execute_reply": "2023-10-05T20:45:40.796778Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.356769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RSNAClassifier(CFG.model_arch, hidden_dim=160, seq_len=CFG.seq_len, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.800472Z",
     "iopub.status.busy": "2023-10-05T20:45:40.800298Z",
     "iopub.status.idle": "2023-10-05T20:45:40.812965Z",
     "shell.execute_reply": "2023-10-05T20:45:40.812339Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.800456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_activation(activ_name: str=\"relu\"):\n",
    "    \"\"\"\"\"\"\n",
    "    act_dict = {\n",
    "        \"relu\": nn.ReLU(inplace=True),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"identity\": nn.Identity()}\n",
    "    if activ_name in act_dict:\n",
    "        return act_dict[activ_name]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class Conv2dBNActiv(nn.Module):\n",
    "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels, out_channels,\n",
    "        kernel_size, stride, padding,\n",
    "        bias=False, use_bn=True, activ=\"relu\"\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(Conv2dBNActiv, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride, padding, bias=bias))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        layers.append(get_activation(activ))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        return self.layers(x)\n",
    "        \n",
    "    \n",
    "class SpatialAttentionBlock(nn.Module):\n",
    "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, in_channels,\n",
    "        out_channels_list,\n",
    "    ):\n",
    "        \"\"\"Initialize\"\"\"\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.n_layers = len(out_channels_list)\n",
    "        channels_list = [in_channels] + out_channels_list\n",
    "        assert self.n_layers > 0\n",
    "        assert channels_list[-1] == 1\n",
    "        \n",
    "        for i in range(self.n_layers - 1):\n",
    "            in_chs, out_chs = channels_list[i: i + 2]\n",
    "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
    "            setattr(self, f\"conv{i + 1}\", layer)\n",
    "            \n",
    "        in_chs, out_chs = channels_list[-2:]\n",
    "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
    "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward\"\"\"\n",
    "        h = x\n",
    "        for i in range(self.n_layers):\n",
    "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
    "            \n",
    "        h = h * x\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadResNet200D(nn.Module):\n",
    "    def __init__(self, out_dims_head=[3, 4, 3, 1],  pretrained=False):\n",
    "        self.base_name = \"resnet200d_320\"\n",
    "        self.n_heads = len(out_dims_head)\n",
    "        super(MultiHeadResNet200D, self).__init__()\n",
    "        \n",
    "        # # load base model\n",
    "        base_model = timm.create_model(self.base_name, num_classes=sum(out_dims_head), pretrained=False)\n",
    "        in_features = base_model.num_features\n",
    "        \n",
    "        if pretrained:\n",
    "            pretrained_model_path = CFG.student\n",
    "            state_dict = dict()\n",
    "            for k, v in torch.load(pretrained_model_path, map_location='cpu')[\"model\"].items():\n",
    "                if k[:6] == \"model.\":\n",
    "                    k = k.replace(\"model.\", \"\")\n",
    "                state_dict[k] = v\n",
    "            base_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # # remove global pooling and head classifier\n",
    "        base_model.reset_classifier(0, '')\n",
    "        \n",
    "        # # Shared CNN Bacbone\n",
    "        self.backbone = base_model\n",
    "        \n",
    "        # # Multi Heads.\n",
    "        for i, out_dim in enumerate(out_dims_head):\n",
    "            layer_name = f\"head_{i}\"\n",
    "            layer = nn.Sequential(\n",
    "                SpatialAttentionBlock(in_features, [64, 32, 16, 1]),\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(in_features, in_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features, out_dim))\n",
    "            setattr(self, layer_name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x)\n",
    "        hs = [getattr(self, f\"head_{i}\")(h) for i in range(self.n_heads)]\n",
    "        y = torch.cat(hs, axis=1)\n",
    "        return None, None, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.814308Z",
     "iopub.status.busy": "2023-10-05T20:45:40.813859Z",
     "iopub.status.idle": "2023-10-05T20:45:40.825507Z",
     "shell.execute_reply": "2023-10-05T20:45:40.825009Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.814285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    for step, (patient_id, images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < CFG.p_mixup:\n",
    "            do_mixup = True\n",
    "            images, labels, labels_mix, lam = mixup(images, labels)\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                y_preds = model(images)\n",
    "                y_preds = y_preds.squeeze(1)\n",
    "                loss = criterion(y_preds, labels)\n",
    "                if do_mixup:\n",
    "                    loss11 = criterion(y_preds, labels_mix)\n",
    "                    loss = loss * lam  + loss11 * (1 - lam)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = 0 # torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        elif CFG.device == 'TPU':\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            if CFG.accum_iter > 1:\n",
    "                loss = loss / CFG.accum_iter\n",
    "            loss.backward()\n",
    "            grad_norm = 0 # torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.accum_iter == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            cusprint('Epoch: [{0}][{1}/{2}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                'Grad: {grad_norm:.4f}  '\n",
    "                'LR: {lr:.7f}  '\n",
    "                .format(\n",
    "                epoch, step, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                grad_norm=grad_norm,\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "                ))\n",
    "        if(step == 0):print(loss)\n",
    "\n",
    "    return losses.avg, optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.826771Z",
     "iopub.status.busy": "2023-10-05T20:45:40.826306Z",
     "iopub.status.idle": "2023-10-05T20:45:40.836507Z",
     "shell.execute_reply": "2023-10-05T20:45:40.835872Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.826747Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tta(images, nbr):\n",
    "    return torch.cat([images[:,nbr:,...], torch.cat(nbr*[images[:,-1:,...]], 1)], 1)\n",
    "    \n",
    "\n",
    "\n",
    "def valid_one_epoch(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (patient, images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)#(model(images) + model(tta(images, 1)))/2\n",
    "            y_preds = y_preds.squeeze(1)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            cusprint('EVAL: [{0}/{1}] '\n",
    "                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                ))\n",
    "\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    print(f\"trues.shape: {trues.shape}\")\n",
    "    print(f\"predictions.shape: {predictions.shape}\")\n",
    "    score = nn.BCEWithLogitsLoss()(torch.from_numpy(predictions).type(torch.float32), torch.from_numpy(trues).type(torch.float32))\n",
    "    p = predictions.copy()\n",
    "    p = sig(p)\n",
    "    p[:, 1] *= 2\n",
    "    p[:, 3] *= 6\n",
    "    p[:, [5, 8, 11]] *= 2\n",
    "    p[:, [6, 9, 12]] *= 4\n",
    "    score2 = comp_metric_score(trues, p)\n",
    "    score3 = roc_auc_score(trues, predictions)\n",
    "    \n",
    "    return losses.avg, predictions, trues, score, score2, score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss & optimizer & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.837582Z",
     "iopub.status.busy": "2023-10-05T20:45:40.837343Z",
     "iopub.status.idle": "2023-10-05T20:45:40.843519Z",
     "shell.execute_reply": "2023-10-05T20:45:40.843017Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.837559Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV3(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV3, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.844688Z",
     "iopub.status.busy": "2023-10-05T20:45:40.844447Z",
     "iopub.status.idle": "2023-10-05T20:45:40.863578Z",
     "shell.execute_reply": "2023-10-05T20:45:40.863090Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.844666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(df, fold):\n",
    "    loginfo(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = df[df['fold']!=fold].reset_index(drop=True)\n",
    "    valid_folds = df[df['fold']==fold].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "#     train_dataset = TrainDataset(train_folds, transform=get_transforms(data='light_train'))\n",
    "#     valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='valid'))\n",
    "    train_dataset = TrainDataset(train_folds, CFG.target_cols, 'train', None, CFG.seq_len, transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, CFG.target_cols, 'valid', None, CFG.seq_len, transform=get_transforms(data='valid'))\n",
    "    if CFG.device == 'GPU':\n",
    "        # sampler_train = torch.utils.data.RandomSampler(ds_train_len)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    elif CFG.device == 'TPU':\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.train_bs, sampler=train_sampler, drop_last=True, num_workers=CFG.num_workers)\n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.valid_bs, sampler=valid_sampler, drop_last=False, num_workers=CFG.num_workers)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer & scheduler & loss\n",
    "    # ====================================================\n",
    "    # not checkpoint\n",
    "\n",
    "    if CFG.multihead:\n",
    "        model = MultiHeadResNet200D([3, 4, 3, 1], True)\n",
    "    else:\n",
    "        model = RSNAClassifier(CFG.model_arch, hidden_dim=128, seq_len=CFG.seq_len, pretrained=True)\n",
    "\n",
    "        \n",
    "    if CFG.gpu_parallel:    \n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        model = DataParallel(model, device_ids=range(num_gpu))\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    # optimizer\n",
    "    if CFG.optimizer == \"AdamW\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    if CFG.optimizer == \"Adam\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = Adam(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    if CFG.optimizer == \"SGD\":\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            optimizer = SGD(model.parameters(), lr=CFG.lr/CFG.warmup_factor, weight_decay=CFG.weight_decay) \n",
    "        else:\n",
    "            optimizer = SGD(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    # scheduler,\n",
    "    if CFG.scheduler=='ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "    elif CFG.scheduler=='CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "\n",
    "    scheduler_warmup = GradualWarmupSchedulerV3(optimizer, multiplier=CFG.warmup_factor, total_epoch=CFG.warmup_epo, after_scheduler=scheduler)\n",
    "\n",
    "    if CFG.loss_fn == \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif CFG.loss_fn == 'Custom_loss':\n",
    "        criterion = Custom_loss()\n",
    "    elif(CFG.loss_fn == 'FocalLoss'):\n",
    "        criterion = FocalLoss()\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    valid_acc_max=0; valid_loss_min=float(\"inf\")\n",
    "    valid_acc_max_cnt=0; valid_loss_min_cnt=0;\n",
    "    best_acc_epoch=0;\n",
    "\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        # if(epoch>=6):break;\n",
    "        # if((fold, epoch) not in [(0, 5), (1, 9), (2, 6), (3, 4), (4, 7)]):continue;\n",
    "        loginfo(f\"***** Epoch {epoch} *****\")\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            loginfo(f\"schwarmup_last_epoch:{scheduler_warmup.last_epoch}, schwarmup_lr:{scheduler_warmup.get_last_lr()[0]}\")\n",
    "        if CFG.scheduler=='CosineAnnealingLR':\n",
    "            loginfo(f\"scheduler_last_epoch:{scheduler.last_epoch}, scheduler_lr:{scheduler.get_last_lr()[0]}\")\n",
    "        loginfo(f\"optimizer_lr:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        if(epoch>=CFG.min_epoch):\n",
    "            avg_loss, cur_lr = train_one_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device) # train\n",
    "        else:\n",
    "            avg_loss, cur_lr = -1, -1\n",
    "            model.load_state_dict(torch.load(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')['model'])\n",
    "        avg_val_loss, preds, trues, score, score2, score3 = valid_one_epoch(valid_loader, model, criterion, device) # valid\n",
    "\n",
    "        # scoring\n",
    "        elapsed = time.time() - start_time \n",
    "\n",
    "        loginfo(f'Epoch {epoch} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        loginfo(f'Epoch {epoch} - valid score: {score:.4f} - valid Custom score: {score2:.4f} - ROC score: {score3:.4f}')\n",
    "\n",
    "        if CFG.scheduler_warmup in [\"GradualWarmupSchedulerV2\",\"GradualWarmupSchedulerV3\"]:\n",
    "            scheduler_warmup.step()\n",
    "        elif CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif CFG.scheduler in [\"CosineAnnealingLR\", \"CosineAnnealingWarmRestarts\"]:\n",
    "            scheduler.step()\n",
    "\n",
    "        # early stopping\n",
    "        if avg_val_loss < valid_loss_min:\n",
    "            valid_loss_min = avg_val_loss\n",
    "            valid_loss_min_cnt=0\n",
    "            best_acc_epoch = epoch\n",
    "        else:\n",
    "            valid_loss_min_cnt+=1\n",
    "\n",
    "        if valid_loss_min_cnt >= CFG.n_early_stopping:\n",
    "            if CFG.device == 'GPU':\n",
    "                torch.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                xm.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "            print(\"early_stopping\")\n",
    "            break\n",
    "        np.save(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}_preds.npy', preds)\n",
    "        np.save(outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}_trues.npy', trues)\n",
    "\n",
    "        if CFG.device == 'GPU':\n",
    "            torch.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "        elif CFG.device == 'TPU':\n",
    "            xm.save({'model': model.state_dict()}, outputdir+f'/{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{epoch}.pth')\n",
    "\n",
    "    return preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.864485Z",
     "iopub.status.busy": "2023-10-05T20:45:40.864249Z",
     "iopub.status.idle": "2023-10-05T20:45:40.869314Z",
     "shell.execute_reply": "2023-10-05T20:45:40.868864Z",
     "shell.execute_reply.started": "2023-10-05T20:45:40.864463Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    oof_df = pd.DataFrame()\n",
    "    oof_list = []\n",
    "    train_df = get_df(CFG.data_dir, use_meta = False)\n",
    "    for fold in CFG.fold_list:\n",
    "        preds, trues = train_loop(train_df, fold)\n",
    "        oof_list.append([preds, trues])\n",
    "    return oof_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:45:40.870359Z",
     "iopub.status.busy": "2023-10-05T20:45:40.870124Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 training ==========\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  warnings.warn(\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n",
      "***** Epoch 0 *****\n",
      "schwarmup_last_epoch:0, schwarmup_lr:5e-06\n",
      "scheduler_last_epoch:0, scheduler_lr:5e-06\n",
      "optimizer_lr:5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/943] Data 2.672 (2.672) Elapsed 0m 9s (remain 143m 21s) Loss: 0.6958(0.6958) Grad: 0.0000  LR: 0.0000050  \n",
      "tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(CFG.suffix)\n",
    "    if CFG.device == 'TPU':\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        oof_list = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save as cpu remain 1978m 41s, remain 64m 18s\n",
    "if CFG.device == 'TPU': \n",
    "    for fold in range(CFG.fold_num):\n",
    "        if fold in CFG.fold_list:\n",
    "            # best score\n",
    "            state = torch.load(outputdir+f'{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{cur_best_list[4]}.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), 'preds': state['preds'], 'cur_best_list': state['cur_best_list']}, \n",
    "                    outputdir+f'{CFG.model_arch}_{CFG.suffix}_fold{fold}_epoch{cur_best_list[4]}_cpu.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
