{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qakPWW5q0CW8"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx5MHrT9fF6S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oVeOBsxJ9ya"
      },
      "outputs": [],
      "source": [
        "#if not os.path.isdir('/content/train_videos'):\n",
        "#    !unzip -q '/content/drive/MyDrive/image224.zip' -d '/content/train_videos'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZnf_ekI7Yvm"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('/content/box'):\n",
        "    !unzip -q '/content/drive/MyDrive/output.zip' -d 'box'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qnoiw4Ek8EK0"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('/content/boxv2'):\n",
        "    !unzip -q '/content/drive/MyDrive/outputv2.zip' -d 'boxv2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('/content/mask'):\n",
        "    !unzip -q '/content/drive/MyDrive/mask.zip' -d 'mask'"
      ],
      "metadata": {
        "id": "zTxa8YQxIFyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG_QDWT-0AsG"
      },
      "source": [
        "## library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjM5SvD10Bzs",
        "outputId": "1fcb8a6a-8031-401f-f18c-f5fec3d419e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.23.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.8.1.78)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom\n",
        "!pip install nibabel\n",
        "!pip install timm\n",
        "!pip install transformers\n",
        "!pip install -U albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ukB9GCw76Wn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import zipfile\n",
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import shutil\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import pydicom #as dicom\n",
        "import nibabel as nib\n",
        "\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "import pandas.api.types\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkZBxiJ-8BVf"
      },
      "source": [
        "## preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYLQG6Nwy-jj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def preprocess():\n",
        "    train_series_meta = pd.read_csv('/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/DataSources/train_series_meta.csv')\n",
        "    train_series_meta = train_series_meta.sort_values(by='patient_id').reset_index(drop=True)\n",
        "    train = pd.read_csv('/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/DataSources/train.csv')\n",
        "    train = train.sort_values(by='patient_id').reset_index(drop=True)\n",
        "    _train = []\n",
        "    series_ids = []\n",
        "    for i in range(len(train_series_meta)):\n",
        "      patient_id, series_id, _, _ = train_series_meta.loc[i]\n",
        "      sample = train[train['patient_id']==patient_id]\n",
        "      _train.append(sample)\n",
        "      series_ids.append(int(series_id))\n",
        "\n",
        "    _train = pd.concat(_train).reset_index(drop=True)\n",
        "    _train['series_id'] = series_ids\n",
        "\n",
        "    train = _train\n",
        "\n",
        "    injury_train = train[train['any_injury']==1].reset_index(drop=True)\n",
        "    normal_train = train[train['any_injury']==0].reset_index(drop=True)\n",
        "\n",
        "    kf = KFold(n_splits=5)\n",
        "    injury_folds = []\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(injury_train)):\n",
        "      train_df = injury_train.loc[train_index]\n",
        "      val_df = injury_train.loc[test_index]\n",
        "      injury_folds.append([train_df, val_df])\n",
        "\n",
        "\n",
        "    kf = KFold(n_splits=5)\n",
        "    normal_folds = []\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(normal_train)):\n",
        "      train_df = normal_train.loc[train_index]\n",
        "      val_df = normal_train.loc[test_index]\n",
        "      normal_folds.append([train_df, val_df])\n",
        "    return train, injury_folds, normal_folds\n",
        "\n",
        "train, injury_folds, normal_folds = preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlcC0YwaBCV5"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1hUseyvBHLQ"
      },
      "outputs": [],
      "source": [
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def normalize_probabilities_to_one(df: pd.DataFrame, group_columns: list) -> pd.DataFrame:\n",
        "    # Normalize the sum of each row's probabilities to 100%.\n",
        "    # 0.75, 0.75 => 0.5, 0.5\n",
        "    # 0.1, 0.1 => 0.5, 0.5\n",
        "    row_totals = df[group_columns].sum(axis=1)\n",
        "    if row_totals.min() == 0:\n",
        "        raise ParticipantVisibleError('All rows must contain at least one non-zero prediction')\n",
        "    for col in group_columns:\n",
        "        df[col] /= row_totals\n",
        "    return df\n",
        "\n",
        "\n",
        "def score(solution_:pd.DataFrame, submission_:pd.DataFrame, row_id_column_name:str, reduction:str ='mean'):\n",
        "    '''\n",
        "    Pseudocode:\n",
        "    1. For every label group (liver, bowel, etc):\n",
        "        - Normalize the sum of each row's probabilities to 100%.\n",
        "        - Calculate the sample weighted log loss.\n",
        "    2. Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n",
        "    3. Calculate the sample weighted log loss for the new label group\n",
        "    4. Return the average of all of the label group log losses as the final score.\n",
        "    '''\n",
        "    solution = solution_.copy()\n",
        "    submission = submission_.copy()\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    # Run basic QC checks on the inputs\n",
        "    if not pandas.api.types.is_numeric_dtype(submission.values):\n",
        "        raise ParticipantVisibleError('All submission values must be numeric')\n",
        "\n",
        "    if not np.isfinite(submission.values).all():\n",
        "        raise ParticipantVisibleError('All submission values must be finite')\n",
        "\n",
        "    if solution.min().min() < 0:\n",
        "        raise ParticipantVisibleError('All labels must be at least zero')\n",
        "    if submission.min().min() < 0:\n",
        "        raise ParticipantVisibleError('All predictions must be at least zero')\n",
        "\n",
        "    # Calculate the label group log losses\n",
        "    binary_targets = ['bowel', 'extravasation']\n",
        "    triple_level_targets = ['kidney', 'liver', 'spleen']\n",
        "    all_target_categories = binary_targets + triple_level_targets\n",
        "\n",
        "    label_group_losses = []\n",
        "    for category in all_target_categories:\n",
        "        if category in binary_targets:\n",
        "            col_group = [f'{category}_healthy', f'{category}_injury']\n",
        "        else:\n",
        "            col_group = [f'{category}_healthy', f'{category}_low', f'{category}_high']\n",
        "\n",
        "        solution = normalize_probabilities_to_one(solution, col_group)\n",
        "\n",
        "        for col in col_group:\n",
        "            if col not in submission.columns:\n",
        "                raise ParticipantVisibleError(f'Missing submission column {col}')\n",
        "        submission = normalize_probabilities_to_one(submission, col_group)\n",
        "        label_group_losses.append(\n",
        "            sklearn.metrics.log_loss(\n",
        "                y_true=solution[col_group].values,\n",
        "                y_pred=submission[col_group].values,\n",
        "                sample_weight=solution[f'{category}_weight'].values\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n",
        "    healthy_cols = [x + '_healthy' for x in all_target_categories]\n",
        "    any_injury_labels = (1 - solution[healthy_cols]).max(axis=1)\n",
        "    any_injury_predictions = (1 - submission[healthy_cols]).max(axis=1)\n",
        "    any_injury_loss = sklearn.metrics.log_loss(\n",
        "        y_true=any_injury_labels.values,\n",
        "        y_pred=any_injury_predictions.values,\n",
        "        sample_weight=solution['any_injury_weight'].values\n",
        "    )\n",
        "\n",
        "    label_group_losses.append(any_injury_loss)\n",
        "    if reduction == 'mean':\n",
        "        return np.mean(label_group_losses)\n",
        "    else:\n",
        "        return label_group_losses\n",
        "\n",
        "# Assign the appropriate weights to each category\n",
        "def create_training_solution(y_train):\n",
        "    sol_train = y_train.copy()\n",
        "\n",
        "    # bowel healthy|injury sample weight = 1|2\n",
        "    sol_train['bowel_weight'] = np.where(sol_train['bowel_injury'] == 1, 2, 1)\n",
        "\n",
        "    # extravasation healthy/injury sample weight = 1|6\n",
        "    sol_train['extravasation_weight'] = np.where(sol_train['extravasation_injury'] == 1, 6, 1)\n",
        "\n",
        "    # kidney healthy|low|high sample weight = 1|2|4\n",
        "    sol_train['kidney_weight'] = np.where(sol_train['kidney_low'] == 1, 2, np.where(sol_train['kidney_high'] == 1, 4, 1))\n",
        "\n",
        "    # liver healthy|low|high sample weight = 1|2|4\n",
        "    sol_train['liver_weight'] = np.where(sol_train['liver_low'] == 1, 2, np.where(sol_train['liver_high'] == 1, 4, 1))\n",
        "\n",
        "    # spleen healthy|low|high sample weight = 1|2|4\n",
        "    sol_train['spleen_weight'] = np.where(sol_train['spleen_low'] == 1, 2, np.where(sol_train['spleen_high'] == 1, 4, 1))\n",
        "\n",
        "    # any healthy|injury sample weight = 1|6\n",
        "    sol_train['any_injury_weight'] = np.where(sol_train['any_injury'] == 1, 6, 1)\n",
        "    return sol_train\n",
        "\n",
        "\n",
        "def get_high_aortic_hu(df):\n",
        "    patient_ids = sorted(df.patient_id.unique())\n",
        "\n",
        "    high_aortic_hu_df = []\n",
        "    for i in range(len(patient_ids)):\n",
        "        patient_id = int(patient_ids[i])\n",
        "        sample = df.query(f'patient_id=={patient_id}').sort_values('aortic_hu', ascending=False).reset_index(drop=True)\n",
        "        sample = sample.loc[0]\n",
        "        high_aortic_hu_df.append(sample)\n",
        "\n",
        "    high_aortic_hu_df = pd.concat(high_aortic_hu_df, axis=1).transpose().reset_index(drop=True)\n",
        "    high_aortic_hu_df = high_aortic_hu_df.astype('int32')\n",
        "    return high_aortic_hu_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcvpAYwQ7Tyu"
      },
      "source": [
        "## preload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJWzyiN98Kzu",
        "outputId": "3c90c23c-5cb0-4361-af20-25faa04ec41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4711/4711 [00:00<00:00, 18598.85it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3147"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ],
      "source": [
        "train, _, _ = preprocess()\n",
        "\n",
        "if not os.path.isdir(f'/content/train_videos'):\n",
        "    os.mkdir(f'/content/train_videos/')\n",
        "\n",
        "for i in tqdm(range(len(train))):\n",
        "    sample = train.loc[i]\n",
        "    patient_id, series_id = int(sample['patient_id']), int(sample['series_id'])\n",
        "\n",
        "    if not os.path.isdir(f'/content/train_videos/{patient_id}'):\n",
        "        os.mkdir(f'/content/train_videos/{patient_id}')\n",
        "\n",
        "len(glob.glob('/content/train_videos/*'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN4CndVS7VCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6362ea04-6508-4e8a-c984-a9699084be1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2356/2356 [29:09<00:00,  1.35it/s]\n"
          ]
        }
      ],
      "source": [
        "class LoadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.df.loc[index]\n",
        "        patient_id, series_id, any_injury = int(sample['patient_id']), int(sample['series_id']), int(sample['any_injury'])\n",
        "\n",
        "        images = np.load(f'/content/drive/MyDrive/train_videos/{patient_id}/{series_id}_images.npy', mmap_mode='r')\n",
        "        crop_liver = np.load(f'/content/drive/MyDrive/train_videos/{patient_id}/{series_id}_liver.npy', mmap_mode='r')\n",
        "        crop_spleen = np.load(f'/content/drive/MyDrive/train_videos/{patient_id}/{series_id}_spleen.npy', mmap_mode='r')\n",
        "        crop_kidney = np.load(f'/content/drive/MyDrive/train_videos/{patient_id}/{series_id}_kidney.npy', mmap_mode='r')\n",
        "\n",
        "        np.save(f'/content/train_videos/{patient_id}/{series_id}_images.npy', images)\n",
        "        np.save(f'/content/train_videos/{patient_id}/{series_id}_liver.npy', crop_liver)\n",
        "        np.save(f'/content/train_videos/{patient_id}/{series_id}_spleen.npy', crop_spleen)\n",
        "        np.save(f'/content/train_videos/{patient_id}/{series_id}_kidney.npy', crop_kidney)\n",
        "\n",
        "        return torch.zeros(1)\n",
        "\n",
        "train, _, _ = preprocess()\n",
        "dataset = LoadDataset(train)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size = 2, num_workers = 12, shuffle = False, drop_last = False)\n",
        "\n",
        "for i, _ in enumerate(tqdm(loader)):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yucDZrAm72Bh"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK24VICOUheE"
      },
      "outputs": [],
      "source": [
        "class CustomAug(nn.Module):\n",
        "    def __init__(self, prob = 0.5, s = 224):\n",
        "        super(CustomAug, self).__init__()\n",
        "        self.prob = prob\n",
        "\n",
        "        self.do_random_rotate = v2.RandomRotation(\n",
        "            degrees = (-45, 45),\n",
        "            interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
        "            expand = False,\n",
        "            center = None,\n",
        "            fill = 0\n",
        "        )\n",
        "        self.do_random_scale = v2.ScaleJitter(\n",
        "            target_size = [s, s],\n",
        "            scale_range = (0.8, 1.2),\n",
        "            interpolation = torchvision.transforms.InterpolationMode.BILINEAR,\n",
        "            antialias = True)\n",
        "\n",
        "        self.do_random_crop = v2.RandomCrop(\n",
        "            size = [s, s],\n",
        "            #padding = None,\n",
        "            pad_if_needed = True,\n",
        "            fill = 0,\n",
        "            padding_mode = 'constant'\n",
        "        )\n",
        "\n",
        "        self.do_horizontal_flip = v2.RandomHorizontalFlip(self.prob)\n",
        "        self.do_vertical_flip = v2.RandomVerticalFlip(self.prob)\n",
        "    def forward(self, x):\n",
        "        if np.random.rand() < self.prob:\n",
        "            x = self.do_random_rotate(x)\n",
        "\n",
        "        if np.random.rand() < self.prob:\n",
        "            x = self.do_random_scale(x)\n",
        "            x = self.do_random_crop(x)\n",
        "\n",
        "        x = self.do_horizontal_flip(x)\n",
        "        x = self.do_vertical_flip(x)\n",
        "        return x\n",
        "\n",
        "aug_function = CustomAug()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usPbfvbOvZ9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78645808-3c51-492f-e23b-5657629d6d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 224, 224])\n",
            "torch.Size([96, 224, 224])\n",
            "torch.Size([96, 224, 224])\n",
            "torch.Size([96, 224, 224])\n",
            "(tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1]), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1.), tensor([1, 1, 1, 1, 1, 1]))\n"
          ]
        }
      ],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, augmentation=False):\n",
        "        self.df = df\n",
        "        self.label_columns = self.df.columns[1:-2]\n",
        "\n",
        "        #self.down_sampling = 1\n",
        "        self.max_frame = 256\n",
        "        self.img_size = 224\n",
        "\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "        self.sample_weights = {\n",
        "            'bowel' : {0:1, 1:2},\n",
        "            'extravasation' : {0:1, 1:6},\n",
        "            'kidney' : {0:1, 1:2, 2:4},\n",
        "            'liver' : {0:1, 1:2, 2:4},\n",
        "            'spleen' : {0:1, 1:2, 2:4},\n",
        "            'any_injury' : {0:1, 1:6}\n",
        "            }\n",
        "\n",
        "        self.sample_weights = {\n",
        "            'bowel' : {0:1, 1:1},\n",
        "            'extravasation' : {0:1, 1:1},\n",
        "            'kidney' : {0:1, 1:1, 2:1},\n",
        "            'liver' : {0:1, 1:1, 2:1},\n",
        "            'spleen' : {0:1, 1:1, 2:1},\n",
        "            'any_injury' : {0:1, 1:1}\n",
        "            }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def get_stride_box(self, min_y, min_x, max_y, max_x, stride=10):\n",
        "        min_y = np.clip(min_y - stride, a_min=0, a_max=512)\n",
        "        min_x = np.clip(min_x - stride, a_min=0, a_max=512)\n",
        "        max_y = np.clip(max_y + stride, a_min=0, a_max=512)\n",
        "        max_x = np.clip(max_x + stride, a_min=0, a_max=512)\n",
        "        return min_y, min_x, max_y, max_x\n",
        "\n",
        "    def get_cropped_organs(self, video, box, ratio=(512/320)):\n",
        "        organs = []\n",
        "        for i in range(box.shape[0]):\n",
        "          min_z, min_y, min_x, max_z, max_y, max_x = box[i]\n",
        "          if 0.0 not in [max_z - min_z, max_y - min_y, max_x - min_x]:\n",
        "            min_y, min_x, max_y, max_x = int(ratio*min_y), int(ratio*min_x), int(ratio*max_y), int(ratio*max_x)\n",
        "            min_y, min_x, max_y, max_x = self.get_stride_box(min_y, min_x, max_y, max_x)\n",
        "            print(max_z-min_z, max_y-min_y, max_x-min_x)\n",
        "            organ = video[min_z:max_z, min_y:max_y, min_x:max_x]\n",
        "          else:\n",
        "            organ = video\n",
        "\n",
        "          organ = F.interpolate(\n",
        "              organ.unsqueeze(0).unsqueeze(0),\n",
        "              size=[96, 224, 224],\n",
        "              mode='trilinear'\n",
        "              ).squeeze(0).squeeze(0)\n",
        "          organs.append(organ)\n",
        "        return organs\n",
        "\n",
        "    def load_image(self, image_path, img_size=512):\n",
        "        return cv2.resize(cv2.imread(image_path)[:,:,0], dsize=(img_size, img_size))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.df.loc[index]\n",
        "        patient_id, series_id, any_injury = int(sample['patient_id']), int(sample['series_id']), int(sample['any_injury'])\n",
        "\n",
        "        '''\n",
        "        images_path = sorted(glob.glob( f'/content/train_images/{int(patient_id)}/{int(series_id)}' + '/*'),key = lambda x : int(x.split('/')[-1].split('.')[0]))\n",
        "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "            images = list(executor.map(self.load_image, images_path))\n",
        "\n",
        "        images = np.stack(images)\n",
        "        images = torch.tensor(images, dtype=torch.float)\n",
        "\n",
        "        images = F.interpolate(\n",
        "            images.unsqueeze(0).unsqueeze(0),\n",
        "            size=[256, 512, 512],\n",
        "            mode='trilinear'\n",
        "            ).squeeze(0).squeeze(0)\n",
        "\n",
        "        box = np.load(f'/content/box/{int(patient_id)}/{int(series_id)}.npy', mmap_mode='r')\n",
        "\n",
        "        organs = self.get_cropped_organs(images, box)\n",
        "        crop_liver, crop_spleen, crop_kidney = organs\n",
        "\n",
        "        images = F.interpolate(\n",
        "            images.unsqueeze(0).unsqueeze(0),\n",
        "            size=[128, 224, 224],\n",
        "            mode='trilinear'\n",
        "            ).squeeze(0).squeeze(0)\n",
        "        '''\n",
        "\n",
        "        images = torch.tensor(np.load(f'/content/train_videos/{patient_id}/{series_id}_images.npy', mmap_mode='r'), dtype=torch.float)\n",
        "        crop_liver = torch.tensor(np.load(f'/content/train_videos/{patient_id}/{series_id}_liver.npy', mmap_mode='r'), dtype=torch.float)\n",
        "        crop_spleen = torch.tensor(np.load(f'/content/train_videos/{patient_id}/{series_id}_spleen.npy', mmap_mode='r'), dtype=torch.float)\n",
        "        crop_kidney = torch.tensor(np.load(f'/content/train_videos/{patient_id}/{series_id}_kidney.npy', mmap_mode='r'), dtype=torch.float)\n",
        "\n",
        "        if self.augmentation:\n",
        "          images = aug_function(images)\n",
        "          crop_liver = aug_function(crop_liver)\n",
        "          crop_spleen = aug_function(crop_spleen)\n",
        "          crop_kidney = aug_function(crop_kidney)\n",
        "\n",
        "        label = torch.tensor(sample[self.label_columns].values, dtype=torch.long)\n",
        "\n",
        "        bowel = label[0:2].argmax()\n",
        "        extravasation = label[2:4].argmax()\n",
        "        kidney = label[4:7].argmax()\n",
        "        liver = label[7:10].argmax()\n",
        "        spleen = label[10:13].argmax()\n",
        "        any_injury = torch.tensor(any_injury, dtype=torch.float)\n",
        "\n",
        "        sample_weights = torch.tensor([\n",
        "            self.sample_weights['bowel'][bowel.tolist()],\n",
        "            self.sample_weights['extravasation'][extravasation.tolist()],\n",
        "            self.sample_weights['kidney'][kidney.tolist()],\n",
        "            self.sample_weights['liver'][liver.tolist()],\n",
        "            self.sample_weights['spleen'][spleen.tolist()],\n",
        "            self.sample_weights['any_injury'][any_injury.tolist()]\n",
        "        ])\n",
        "\n",
        "        images, crop_liver, crop_spleen, crop_kidney = images/255.0, crop_liver/255.0, crop_spleen/255.0, crop_kidney/255.0\n",
        "\n",
        "        return images, crop_liver, crop_spleen, crop_kidney, label, bowel, extravasation, kidney, liver, spleen, any_injury, sample_weights\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #train, _, _ = preprocess()\n",
        "    dataset = CustomDataset(train, False)\n",
        "    index = np.random.randint(0, len(train)-1)\n",
        "    sample = dataset[index]\n",
        "    print(sample[0].shape)\n",
        "    print(sample[1].shape)\n",
        "    print(sample[2].shape)\n",
        "    print(sample[3].shape)\n",
        "    print(sample[4:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7JI_rQBmrQL"
      },
      "outputs": [],
      "source": [
        "id = 48\n",
        "\n",
        "index = np.random.randint(0, len(train)-1)\n",
        "sample = dataset[index]\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
        "axs[0, 0].imshow(sample[0][id], cmap='gray')\n",
        "axs[0, 1].imshow(sample[1][id], cmap='gray')\n",
        "axs[1, 0].imshow(sample[2][id], cmap='gray')\n",
        "axs[1, 1].imshow(sample[3][id], cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axg4OkSm70W6"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYRDRZwXPZ92"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaPreLayerNormConfig, RobertaPreLayerNormModel\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, hidden, num_channel):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "\n",
        "        self.hidden = hidden\n",
        "        self.num_channel = num_channel\n",
        "\n",
        "        self.cnn = timm.create_model(model_name = 'regnety_002',\n",
        "                                     pretrained = True,\n",
        "                                     num_classes = 0,\n",
        "                                     in_chans = num_channel)\n",
        "\n",
        "        self.fc = nn.Linear(hidden, hidden//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_frame, h, w = x.shape\n",
        "        x = x.reshape(batch_size, num_frame//self.num_channel, self.num_channel, h, w)\n",
        "        x = x.reshape(-1, self.num_channel, h, w)\n",
        "        x = self.cnn(x)\n",
        "        x = x.reshape(batch_size, num_frame//self.num_channel, self.hidden)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ContextProcessor(nn.Module):\n",
        "    def __init__(self, hidden):\n",
        "        super(ContextProcessor, self).__init__()\n",
        "        self.transformer = RobertaPreLayerNormModel(\n",
        "            RobertaPreLayerNormConfig(\n",
        "                hidden_size = hidden//2,\n",
        "                num_hidden_layers = 1,\n",
        "                num_attention_heads = 4,\n",
        "                intermediate_size = hidden*2,\n",
        "                hidden_act = 'gelu_new',\n",
        "                )\n",
        "            )\n",
        "\n",
        "        del self.transformer.embeddings.word_embeddings\n",
        "\n",
        "        self.dense = nn.Linear(hidden, hidden)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.transformer(inputs_embeds = x).last_hidden_state\n",
        "\n",
        "        apool = torch.mean(x, dim = 1)\n",
        "        mpool, _ = torch.max(x, dim = 1)\n",
        "        x = torch.cat([mpool, apool], dim = -1)\n",
        "\n",
        "        x = self.dense(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class Custom3DCNN(nn.Module):\n",
        "    def __init__(self, hidden = 368, num_channel = 2):\n",
        "        super(Custom3DCNN, self).__init__()\n",
        "\n",
        "        self.full_extractor = FeatureExtractor(hidden=hidden, num_channel=num_channel)\n",
        "        self.kidney_extractor = FeatureExtractor(hidden=hidden, num_channel=num_channel)\n",
        "        self.liver_extractor = FeatureExtractor(hidden=hidden, num_channel=num_channel)\n",
        "        self.spleen_extractor = FeatureExtractor(hidden=hidden, num_channel=num_channel)\n",
        "\n",
        "        self.full_processor = ContextProcessor(hidden=hidden)\n",
        "        self.kidney_processor = ContextProcessor(hidden=hidden)\n",
        "        self.liver_processor = ContextProcessor(hidden=hidden)\n",
        "        self.spleen_processor = ContextProcessor(hidden=hidden)\n",
        "\n",
        "        self.bowel = nn.Linear(hidden, 2)\n",
        "        self.extravasation = nn.Linear(hidden, 2)\n",
        "        self.kidney = nn.Linear(hidden, 3)\n",
        "        self.liver = nn.Linear(hidden, 3)\n",
        "        self.spleen = nn.Linear(hidden, 3)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim = -1)\n",
        "\n",
        "    def forward(self, full_input, crop_liver, crop_spleen, crop_kidney, mask, mode):\n",
        "        full_output = self.full_extractor(full_input)\n",
        "        kidney_output = self.kidney_extractor(crop_kidney)\n",
        "        liver_output = self.liver_extractor(crop_liver)\n",
        "        spleen_output = self.spleen_extractor(crop_spleen)\n",
        "\n",
        "        full_output2 = self.full_processor(torch.cat([full_output, kidney_output, liver_output, spleen_output], dim = 1))\n",
        "        kidney_output2 = self.kidney_processor(torch.cat([full_output, kidney_output], dim = 1))\n",
        "        liver_output2 = self.liver_processor(torch.cat([full_output, liver_output], dim = 1))\n",
        "        spleen_output2 = self.spleen_processor(torch.cat([full_output, spleen_output], dim = 1))\n",
        "\n",
        "        bowel = self.bowel(full_output2)\n",
        "        extravasation = self.extravasation(full_output2)\n",
        "        kidney = self.kidney(kidney_output2)\n",
        "        liver = self.liver(liver_output2)\n",
        "        spleen = self.spleen(spleen_output2)\n",
        "\n",
        "\n",
        "        any_injury = torch.stack([\n",
        "            self.softmax(bowel)[:, 0],\n",
        "            self.softmax(extravasation)[:, 0],\n",
        "            self.softmax(kidney)[:, 0],\n",
        "            self.softmax(liver)[:, 0],\n",
        "            self.softmax(spleen)[:, 0]\n",
        "        ], dim = -1)\n",
        "        any_injury = 1 - any_injury\n",
        "        any_injury, _ = any_injury.max(1)\n",
        "        return bowel, extravasation, kidney, liver, spleen, any_injury"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb1VdSbq5Uoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "c2fd857e1cc744d6aa7541d4f51d82db",
            "9d9250bdfff14a239d1a57c53c9e4ef2",
            "41b142458d4a4d689529c512db052bce",
            "3952be6ebf94495dbb9fb8482b4ff39b",
            "efe32d3c9d9c44e3af3eee256b6e3da7",
            "e9f250782c68483ba89b1045cf08e88e",
            "88c70397c3794ecaac6479c2c6efec14",
            "0a2007f5f6bb4f75bee751485bafb64e",
            "4c7804bad92c4b119f83bf7c6b016c45",
            "636739771db343deb3942d16155e7600",
            "24ae6341ac44466fbfadacbc27cb7a3e"
          ]
        },
        "outputId": "a94724a5-bd41-4acf-d9d1-1c1af99e4838"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/67.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2fd857e1cc744d6aa7541d4f51d82db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[0.2819, 0.2997],\n",
            "        [0.3204, 0.3262]], device='cuda:0'), tensor([[-0.2597, -0.1033],\n",
            "        [-0.3401, -0.1753]], device='cuda:0'), tensor([[-0.1039,  0.3544,  0.8981],\n",
            "        [-0.0786,  0.2911,  0.8833]], device='cuda:0'), tensor([[ 0.5575, -0.0765, -0.3373],\n",
            "        [ 0.4492, -0.0638, -0.4594]], device='cuda:0'), tensor([[ 0.0694,  0.3060, -0.4675],\n",
            "        [-0.0050,  0.2950, -0.4781]], device='cuda:0'), tensor([0.5977, 0.6018], device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "model = Custom3DCNN().to(device).float()\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size = 2, num_workers = 2, shuffle = True, drop_last = True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample = next(iter(loader))\n",
        "    output = model(sample[0].to(device), sample[1].to(device), sample[2].to(device), sample[3].to(device), sample[4].to(device), mode = 'train')\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndeLVoeU7tw3"
      },
      "source": [
        "## train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9BMobOoFk3b"
      },
      "outputs": [],
      "source": [
        "def train_function(model,\n",
        "                   optimizer,\n",
        "                   scheduler,\n",
        "                   loss_functions,\n",
        "                   scaler,\n",
        "                   loader,\n",
        "                   device,\n",
        "                   iters_to_accumulate):\n",
        "    model.train()\n",
        "\n",
        "    total_bowel_loss = 0.0\n",
        "    total_extravasation_loss = 0.0\n",
        "    total_kidney_loss = 0.0\n",
        "    total_liver_loss = 0.0\n",
        "    total_spleen_loss = 0.0\n",
        "    total_any_injury_loss = 0.0\n",
        "\n",
        "    total_bowel_weight = 0.0\n",
        "    total_extravasation_weight = 0.0\n",
        "    total_kidney_weight = 0.0\n",
        "    total_liver_weight = 0.0\n",
        "    total_spleen_weight = 0.0\n",
        "    total_any_injury_weight = 0.0\n",
        "    for bi, sample in enumerate(tqdm(loader)):\n",
        "        sample = [x.to(device) for x in sample]\n",
        "        video, crop_liver, crop_spleen, crop_kidney, label, bowel, extravasation, kidney, liver, spleen, any_injury, sample_weights = sample\n",
        "\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            bowel_output, extravasation_output, kidney_output, liver_output, spleen_output, any_injury_output = model(video, crop_liver, crop_spleen, crop_kidney, label, mode = 'test')\n",
        "\n",
        "        bowel_loss = (loss_functions[0](bowel_output, bowel) * sample_weights[:, 0]).sum()\n",
        "        extravasation_loss = (loss_functions[0](extravasation_output, extravasation) * sample_weights[:, 1]).sum()\n",
        "        kidney_loss = (loss_functions[0](kidney_output, kidney) * sample_weights[:, 2]).sum()\n",
        "        liver_loss = (loss_functions[0](liver_output, liver) * sample_weights[:, 3]).sum()\n",
        "        spleen_loss = (loss_functions[0](spleen_output, spleen) * sample_weights[:, 4]).sum()\n",
        "        any_injury_loss = (loss_functions[1](any_injury_output, any_injury) * sample_weights[:, 5]).sum()\n",
        "\n",
        "        loss = (\n",
        "            bowel_loss / sample_weights[:, 0].sum()+ \\\n",
        "            extravasation_loss / sample_weights[:, 1].sum()+ \\\n",
        "            kidney_loss / sample_weights[:, 2].sum() + \\\n",
        "            liver_loss / sample_weights[:, 3].sum()+ \\\n",
        "            spleen_loss / sample_weights[:, 4].sum()#+ \\\n",
        "            #any_injury_loss / sample_weights[:, 5].sum()\n",
        "            )\n",
        "        loss = loss / 5\n",
        "\n",
        "        loss = loss / iters_to_accumulate\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if (bi + 1) % iters_to_accumulate == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "        total_bowel_loss += bowel_loss.detach().cpu()\n",
        "        total_extravasation_loss += extravasation_loss.detach().cpu()\n",
        "        total_kidney_loss += kidney_loss.detach().cpu()\n",
        "        total_liver_loss += liver_loss.detach().cpu()\n",
        "        total_spleen_loss += spleen_loss.detach().cpu()\n",
        "        total_any_injury_loss += any_injury_loss.detach().cpu()\n",
        "\n",
        "        total_bowel_weight += sample_weights[:, 0].sum().cpu()\n",
        "        total_extravasation_weight += sample_weights[:, 1].sum().cpu()\n",
        "        total_kidney_weight += sample_weights[:, 2].sum().cpu()\n",
        "        total_liver_weight += sample_weights[:, 3].sum().cpu()\n",
        "        total_spleen_weight += sample_weights[:, 4].sum().cpu()\n",
        "        total_any_injury_weight += sample_weights[:, 5].sum().cpu()\n",
        "\n",
        "    total_bowel_loss = total_bowel_loss / total_bowel_weight\n",
        "    total_extravasation_loss = total_extravasation_loss / total_extravasation_weight\n",
        "    total_kidney_loss = total_kidney_loss / total_kidney_weight\n",
        "    total_liver_loss = total_liver_loss / total_liver_weight\n",
        "    total_spleen_loss = total_spleen_loss / total_spleen_weight\n",
        "    total_any_injury_loss  = total_any_injury_loss / total_any_injury_weight\n",
        "\n",
        "    total_loss = (total_bowel_loss + total_extravasation_loss + total_kidney_loss + total_liver_loss + total_spleen_loss + total_any_injury_loss)/6\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def test_function(model,\n",
        "                  loader,\n",
        "                  device,\n",
        "                  input_df,\n",
        "                  temperature=1.0):\n",
        "\n",
        "    test_df = input_df.copy()\n",
        "    true_df = input_df.copy()\n",
        "    model.eval()\n",
        "\n",
        "    # competition metric\n",
        "    bowel_healthy = []\n",
        "    bowel_injury = []\n",
        "    extravasation_healthy = []\n",
        "    extravasation_injury = []\n",
        "    kidney_healthy = []\n",
        "    kidney_low = []\n",
        "    kidney_high = []\n",
        "    liver_healthy = []\n",
        "    liver_low = []\n",
        "    liver_high = []\n",
        "    spleen_healthy = []\n",
        "    spleen_low = []\n",
        "    spleen_high = []\n",
        "\n",
        "    # auc\n",
        "    bowel_preds = []\n",
        "    extravasation_preds = []\n",
        "    kidney_preds = []\n",
        "    liver_preds = []\n",
        "    spleen_preds = []\n",
        "    any_injury_preds = []\n",
        "\n",
        "    bowel_trues = []\n",
        "    extravasation_trues = []\n",
        "    kidney_trues = []\n",
        "    liver_trues = []\n",
        "    spleen_trues = []\n",
        "    any_injury_trues = []\n",
        "\n",
        "    for bi, sample in enumerate(tqdm(loader)):\n",
        "        sample = [x.to(device) for x in sample]\n",
        "        video, crop_liver, crop_spleen, crop_kidney, label, bowel, extravasation, kidney, liver, spleen, any_injury, _ = sample\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(video, crop_liver, crop_spleen, crop_kidney, label, mode = 'test')\n",
        "\n",
        "        bowel_output = nn.Softmax(dim=-1)(output[0].cpu()/temperature)\n",
        "        extravasation_output = nn.Softmax(dim=-1)(output[1].cpu()/temperature)\n",
        "        kidney_output = nn.Softmax(dim=-1)(output[2].cpu()/temperature)\n",
        "        liver_output = nn.Softmax(dim=-1)(output[3].cpu()/temperature)\n",
        "        spleen_output = nn.Softmax(dim=-1)(output[4].cpu()/temperature)\n",
        "        any_injury_output = output[5].cpu()\n",
        "\n",
        "        bowel_healthy.extend(bowel_output[:, 0].tolist())\n",
        "        bowel_injury.extend(bowel_output[:, 1].tolist())\n",
        "        extravasation_healthy.extend(extravasation_output[:, 0].tolist())\n",
        "        extravasation_injury.extend(extravasation_output[:, 1].tolist())\n",
        "        kidney_healthy.extend(kidney_output[:, 0].tolist())\n",
        "        kidney_low.extend(kidney_output[:, 1].tolist())\n",
        "        kidney_high.extend(kidney_output[:, 2].tolist())\n",
        "        liver_healthy.extend(liver_output[:, 0].tolist())\n",
        "        liver_low.extend(liver_output[:, 1].tolist())\n",
        "        liver_high.extend(liver_output[:, 2].tolist())\n",
        "        spleen_healthy.extend(spleen_output[:, 0].tolist())\n",
        "        spleen_low.extend(spleen_output[:, 1].tolist())\n",
        "        spleen_high.extend(spleen_output[:, 2].tolist())\n",
        "\n",
        "        bowel_preds.extend(bowel_output[:, 1].tolist())\n",
        "        extravasation_preds.extend(extravasation_output[:, 1].tolist())\n",
        "        kidney_preds.extend(kidney_output.tolist())\n",
        "        liver_preds.extend(liver_output.tolist())\n",
        "        spleen_preds.extend(spleen_output.tolist())\n",
        "        any_injury_preds.extend(any_injury_output.tolist())\n",
        "\n",
        "        bowel_trues.extend(bowel.tolist())\n",
        "        extravasation_trues.extend(extravasation.tolist())\n",
        "        kidney_trues.extend(kidney.tolist())\n",
        "        liver_trues.extend(liver.tolist())\n",
        "        spleen_trues.extend(spleen.tolist())\n",
        "        any_injury_trues.extend(any_injury.tolist())\n",
        "\n",
        "    test_df['bowel_healthy'] = bowel_healthy\n",
        "    test_df['bowel_injury'] = bowel_injury\n",
        "    test_df['extravasation_healthy'] = extravasation_healthy\n",
        "    test_df['extravasation_injury'] = extravasation_injury\n",
        "    test_df['kidney_healthy'] = kidney_healthy\n",
        "    test_df['kidney_low'] = kidney_low\n",
        "    test_df['kidney_high'] = kidney_high\n",
        "    test_df['liver_healthy'] = liver_healthy\n",
        "    test_df['liver_low'] = liver_low\n",
        "    test_df['liver_high'] = liver_high\n",
        "    test_df['spleen_healthy'] = spleen_healthy\n",
        "    test_df['spleen_low'] = spleen_low\n",
        "    test_df['spleen_high'] = spleen_high\n",
        "\n",
        "    test_score = score(create_training_solution(true_df), test_df, 'patient_id', reduction='none')\n",
        "\n",
        "    bowel_auc = roc_auc_score(bowel_trues, bowel_preds)\n",
        "    extravasation_auc = roc_auc_score(extravasation_trues, extravasation_preds)\n",
        "    kidney_auc = roc_auc_score(kidney_trues, kidney_preds, multi_class = 'ovr')\n",
        "    liver_auc = roc_auc_score(liver_trues, liver_preds, multi_class = 'ovr')\n",
        "    spleen_auc = roc_auc_score(spleen_trues, spleen_preds, multi_class = 'ovr')\n",
        "    any_injury_auc = roc_auc_score(any_injury_trues, any_injury_preds)\n",
        "\n",
        "    message = {\n",
        "        'weighted-log-loss' : {\n",
        "            'bowel' : round(test_score[0], 4),\n",
        "            'extravasation' : round(test_score[1], 4),\n",
        "            'kidney' : round(test_score[2], 4),\n",
        "            'liver' : round(test_score[3], 4),\n",
        "            'spleen' : round(test_score[4], 4),\n",
        "            'any_injury' : round(test_score[5], 4),\n",
        "            'score' : round(np.mean(test_score), 4)\n",
        "        },\n",
        "\n",
        "        'auc' : {\n",
        "            'bowel' : round(bowel_auc, 4),\n",
        "            'extravasation' : round(extravasation_auc, 4),\n",
        "            'kidney' : round(kidney_auc, 4),\n",
        "            'liver' : round(liver_auc, 4),\n",
        "            'spleen' : round(spleen_auc, 4),\n",
        "            'any_injury' : round(any_injury_auc, 4)\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return test_df, torch.tensor(test_score).mean(), message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohwHmw7vfbvb"
      },
      "source": [
        "## run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYDzK4op6Zk4"
      },
      "outputs": [],
      "source": [
        "for k in range(5):\n",
        "    device = 'cuda'\n",
        "    epoch = 20\n",
        "    batch_size = 4\n",
        "    lr = 2e-4\n",
        "    wd = 0.01\n",
        "    warmup_ratio = 0.1\n",
        "    num_workers = 12\n",
        "    iters_to_accumulate = 4\n",
        "    label_smoothing = 0.0\n",
        "    early_stop_epoch = 15\n",
        "    dir_name = 'result-channel2-512'\n",
        "\n",
        "    train, injury_folds, normal_folds = preprocess()\n",
        "\n",
        "    train_df = pd.concat([injury_folds[k][0]] + [normal_folds[k][0]]).reset_index(drop=True)\n",
        "    val_df = pd.concat([injury_folds[k][1], normal_folds[k][1]]).reset_index(drop=True)\n",
        "\n",
        "    train_dataset = CustomDataset(train_df, augmentation=True)\n",
        "    val_dataset = CustomDataset(val_df)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True, drop_last = True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = False, drop_last = False)\n",
        "\n",
        "\n",
        "    model = Custom3DCNN().to(device).float()\n",
        "\n",
        "    loss_functions = [\n",
        "        nn.CrossEntropyLoss(label_smoothing = label_smoothing, reduction='none'),\n",
        "        nn.BCELoss(reduction='none')\n",
        "    ]\n",
        "\n",
        "    optimizer = torch.optim.AdamW(params = model.parameters(), lr = lr, weight_decay = wd)\n",
        "    total_steps = int(len(train_df) * epoch/(batch_size * iters_to_accumulate))\n",
        "    warmup_steps = int(total_steps * warmup_ratio)\n",
        "    print('total_steps: ', total_steps)\n",
        "    print('warmup_steps: ', warmup_steps)\n",
        "\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps = warmup_steps,\n",
        "                                                num_training_steps = total_steps)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    if not os.path.isdir(f'/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/{dir_name}/'):\n",
        "      os.mkdir(f'/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/{dir_name}/')\n",
        "\n",
        "    if not os.path.isdir(f'/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/{dir_name}/fold{k+1}/'):\n",
        "      os.mkdir(f'/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/{dir_name}/fold{k+1}/')\n",
        "\n",
        "    log_path = f'/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/{dir_name}/fold{k+1}/log.txt'\n",
        "\n",
        "\n",
        "    for i in range(epoch):\n",
        "        print(f'{i+1}th epoch training is start...')\n",
        "\n",
        "        if i==early_stop_epoch:\n",
        "          break\n",
        "\n",
        "        # train\n",
        "        train_loss = train_function(model,\n",
        "                                    optimizer,\n",
        "                                    scheduler,\n",
        "                                    loss_functions,\n",
        "                                    scaler,\n",
        "                                    train_loader,\n",
        "                                    device,\n",
        "                                    iters_to_accumulate)\n",
        "\n",
        "        # val\n",
        "        _, val_loss, message = test_function(model,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              val_loader.dataset.df.copy())\n",
        "\n",
        "\n",
        "        # save\n",
        "        save_path = f'/content/drive/MyDrive/Kaggle/RSNA 2023 Abdominal Trauma Detection/{dir_name}/fold{k+1}/epoch' + f'{i+1}'.zfill(3) + \\\n",
        "                    f'-trainloss{round(train_loss.tolist(), 4)}' + \\\n",
        "                    f'-valloss{round(val_loss.tolist(), 4)}' + '.bin'\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        _lr = optimizer.param_groups[0]['lr']\n",
        "        message['log'] = f'epoch : {i+1}, lr : {_lr}, trainloss : {round(train_loss.tolist(), 4)}, valloss : {round(val_loss.tolist(), 4)}'\n",
        "        print(message)\n",
        "        with open(log_path, 'a+') as logger:\n",
        "            logger.write(f'{message}\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qakPWW5q0CW8",
        "AG_QDWT-0AsG",
        "IkZBxiJ-8BVf",
        "RlcC0YwaBCV5",
        "ndeLVoeU7tw3"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2fd857e1cc744d6aa7541d4f51d82db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d9250bdfff14a239d1a57c53c9e4ef2",
              "IPY_MODEL_41b142458d4a4d689529c512db052bce",
              "IPY_MODEL_3952be6ebf94495dbb9fb8482b4ff39b"
            ],
            "layout": "IPY_MODEL_efe32d3c9d9c44e3af3eee256b6e3da7"
          }
        },
        "9d9250bdfff14a239d1a57c53c9e4ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f250782c68483ba89b1045cf08e88e",
            "placeholder": "​",
            "style": "IPY_MODEL_88c70397c3794ecaac6479c2c6efec14",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "41b142458d4a4d689529c512db052bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2007f5f6bb4f75bee751485bafb64e",
            "max": 67412686,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c7804bad92c4b119f83bf7c6b016c45",
            "value": 67412686
          }
        },
        "3952be6ebf94495dbb9fb8482b4ff39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636739771db343deb3942d16155e7600",
            "placeholder": "​",
            "style": "IPY_MODEL_24ae6341ac44466fbfadacbc27cb7a3e",
            "value": " 67.4M/67.4M [00:05&lt;00:00, 14.1MB/s]"
          }
        },
        "efe32d3c9d9c44e3af3eee256b6e3da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f250782c68483ba89b1045cf08e88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c70397c3794ecaac6479c2c6efec14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2007f5f6bb4f75bee751485bafb64e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7804bad92c4b119f83bf7c6b016c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "636739771db343deb3942d16155e7600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ae6341ac44466fbfadacbc27cb7a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
